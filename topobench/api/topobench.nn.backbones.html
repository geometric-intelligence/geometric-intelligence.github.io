
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>topobench.nn.backbones package &#8212; TopoBench latest documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=93df839b" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=c6e86fd7"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/topobench.nn.backbones';</script>
    <link rel="canonical" href="https://geometric-intelligence.github.io/topobench/api/topobench.nn.backbones.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="topobench.nn.backbones.cell package" href="topobench.nn.backbones.cell.html" />
    <link rel="prev" title="topobench.nn package" href="topobench.nn.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="latest" />
    <meta name="docbuild:last-update" content="Oct 27, 2025, 10:47:55 PM"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">TopoBench latest documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tdl-challenge/index.html">
    TAG-DS TDL Challenge 2025
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing/index.html">
    Contributing
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../tdl-challenge/index.html">
    TAG-DS TDL Challenge 2025
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing/index.html">
    Contributing
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">API Reference</a></li>
    
    
    <li class="breadcrumb-item"><a href="topobench.html" class="nav-link">topobench package</a></li>
    
    
    <li class="breadcrumb-item"><a href="topobench.nn.html" class="nav-link">topobench.nn package</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">topobench.nn.backbones package</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="module-topobench.nn.backbones">
<span id="topobench-nn-backbones-package"></span><h1>topobench.nn.backbones package<a class="headerlink" href="#module-topobench.nn.backbones" title="Link to this heading">#</a></h1>
<p>Some models implemented for TopoBenchX with automated exports.</p>
<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.CCCN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">CCCN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.CCCN" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>CCCN model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">int</span></dt><dd><p>Number of input channels.</p>
</dd>
<dt><strong>n_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers (default: 2).</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate (default: 0).</p>
</dd>
<dt><strong>last_act</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, the last activation function is applied (default: False).</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.CCCN.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.CCCN.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.CCCN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ld</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lu</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.CCCN.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor.</p>
</dd>
<dt><strong>Ld</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Domain adjacency matrix.</p>
</dd>
<dt><strong>Lu</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Label adjacency matrix.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output tensor.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.CW">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">CW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">F_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F_out</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.CW" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Layer of the CCCN model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>F_in</strong><span class="classifier">int</span></dt><dd><p>Number of input channels.</p>
</dd>
<dt><strong>F_out</strong><span class="classifier">int</span></dt><dd><p>Number of output channels.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.CW.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">F_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F_out</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.CW.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.CW.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xe</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lu</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Ld</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.CW.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>xe</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor.</p>
</dd>
<dt><strong>Lu</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Domain adjacency matrix.</p>
</dd>
<dt><strong>Ld</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Label adjacency matrix.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output tensor.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.EDGNN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">EDGNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">MLP_num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">MLP2_num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">MLP3_num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">All_num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edconv_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'EquivSet'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">restart_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'add'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'None'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">AllSet_input_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.EDGNN" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>EDGNN model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>num_features</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>input_dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate for input features. Defaults to 0.2.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate for hidden layers. Defaults to 0.2.</p>
</dd>
<dt><strong>activation</strong><span class="classifier">str, optional</span></dt><dd><p>Activation function. Defaults to ‘relu’.</p>
</dd>
<dt><strong>MLP_num_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in MLP. Defaults to 2.</p>
</dd>
<dt><strong>MLP2_num_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the second MLP. Defaults to -1.</p>
</dd>
<dt><strong>MLP3_num_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the third MLP. Defaults to -1.</p>
</dd>
<dt><strong>All_num_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the EDConv. Defaults to 2.</p>
</dd>
<dt><strong>edconv_type</strong><span class="classifier">str, optional</span></dt><dd><p>Type of EDConv. Defaults to ‘EquivSet’.</p>
</dd>
<dt><strong>restart_alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Restart alpha. Defaults to 0.5.</p>
</dd>
<dt><strong>aggregate</strong><span class="classifier">str, optional</span></dt><dd><p>Aggregation method. Defaults to ‘add’.</p>
</dd>
<dt><strong>normalization</strong><span class="classifier">str, optional</span></dt><dd><p>Normalization method. Defaults to ‘None’.</p>
</dd>
<dt><strong>AllSet_input_norm</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to normalize input features. Defaults to False.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.EDGNN.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">MLP_num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">MLP2_num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">MLP3_num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">All_num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edconv_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'EquivSet'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">restart_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'add'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'None'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">AllSet_input_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.EDGNN.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.EDGNN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.EDGNN.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">Tensor</span></dt><dd><p>Input features.</p>
</dd>
<dt><strong>edge_index</strong><span class="classifier">LongTensor</span></dt><dd><p>Edge index.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>Tensor</dt><dd><p>Output features.</p>
</dd>
<dt>None</dt><dd><p>None object needed for compatibility.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.EDGNN.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.EDGNN.reset_parameters" title="Link to this definition">#</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.EquivSetConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">EquivSetConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp1_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp2_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp3_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'add'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'None'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.EquivSetConv" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Class implementing the Equivariant Set Convolution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_features</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>out_features</strong><span class="classifier">int</span></dt><dd><p>Number of output features.</p>
</dd>
<dt><strong>mlp1_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the first MLP. Defaults to 1.</p>
</dd>
<dt><strong>mlp2_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the second MLP. Defaults to 1.</p>
</dd>
<dt><strong>mlp3_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the third MLP. Defaults to 1.</p>
</dd>
<dt><strong>aggr</strong><span class="classifier">str, optional</span></dt><dd><p>Aggregation method. Defaults to ‘add’.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Alpha value. Defaults to 0.5.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate. Defaults to 0.0.</p>
</dd>
<dt><strong>normalization</strong><span class="classifier">str, optional</span></dt><dd><p>Normalization method. Defaults to ‘None’.</p>
</dd>
<dt><strong>input_norm</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to normalize input features. Defaults to False.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.EquivSetConv.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp1_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp2_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp3_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'add'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'None'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.EquivSetConv.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.EquivSetConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vertex</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edges</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.EquivSetConv.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">Tensor</span></dt><dd><p>Input features.</p>
</dd>
<dt><strong>vertex</strong><span class="classifier">LongTensor</span></dt><dd><p>Vertex index.</p>
</dd>
<dt><strong>edges</strong><span class="classifier">LongTensor</span></dt><dd><p>Edge index.</p>
</dd>
<dt><strong>X0</strong><span class="classifier">Tensor</span></dt><dd><p>Initial features.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>Tensor</dt><dd><p>Output features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.EquivSetConv.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.EquivSetConv.reset_parameters" title="Link to this definition">#</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.GPSEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">GPSEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'multihead'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_conv_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gin'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_edge_attr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">redraw_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.GPSEncoder" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>GPS Encoder that can be used with the training framework.</p>
<p>Uses the official PyTorch Geometric GPSConv implementation.
This encoder combines local message passing with global attention mechanisms
for powerful graph representation learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>input_dim</strong><span class="classifier">int</span></dt><dd><p>Dimension of input node features.</p>
</dd>
<dt><strong>hidden_dim</strong><span class="classifier">int</span></dt><dd><p>Dimension of hidden layers.</p>
</dd>
<dt><strong>num_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of GPS layers. Default is 4.</p>
</dd>
<dt><strong>heads</strong><span class="classifier">int, optional</span></dt><dd><p>Number of attention heads in GPSConv layers. Default is 4.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate for GPSConv layers. Default is 0.1.</p>
</dd>
<dt><strong>attn_type</strong><span class="classifier">str, optional</span></dt><dd><p>Type of attention mechanism to use. Options are ‘multihead’, ‘performer’, etc.
Default is ‘multihead’.</p>
</dd>
<dt><strong>local_conv_type</strong><span class="classifier">str, optional</span></dt><dd><p>Type of local message passing layer. Options are ‘gin’, ‘pna’, etc.
Default is ‘gin’.</p>
</dd>
<dt><strong>use_edge_attr</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to use edge attributes in GPSConv layers. Default is False.</p>
</dd>
<dt><strong>redraw_interval</strong><span class="classifier">int or None, optional</span></dt><dd><p>Interval for redrawing random projections in Performer attention.
If None, projections are not redrawn. Default is None.</p>
</dd>
<dt><strong>attn_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Additional keyword arguments for the attention mechanism.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.GPSEncoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'multihead'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_conv_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gin'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_edge_attr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">redraw_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attn_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.GPSEncoder.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.GPSEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_attr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.GPSEncoder.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass of GPS encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Node feature matrix of shape [num_nodes, input_dim].</p>
</dd>
<dt><strong>edge_index</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Edge indices of shape [2, num_edges].</p>
</dd>
<dt><strong>batch</strong><span class="classifier">torch.Tensor, optional</span></dt><dd><p>Batch vector assigning each node to a specific graph. Shape [num_nodes]. Default is None.</p>
</dd>
<dt><strong>edge_attr</strong><span class="classifier">torch.Tensor, optional</span></dt><dd><p>Edge feature matrix of shape [num_edges, edge_dim]. Default is None.</p>
</dd>
<dt><strong>**kwargs</strong><span class="classifier">dict</span></dt><dd><p>Additional arguments (not used).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output node feature matrix of shape [num_nodes, hidden_dim].</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.GraphMLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">GraphMLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.GraphMLP" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>“Graph MLP backbone.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>hidden_channels</strong><span class="classifier">int</span></dt><dd><p>Number of hidden units.</p>
</dd>
<dt><strong>order</strong><span class="classifier">int, optional</span></dt><dd><p>To compute order-th power of adj matrix (default: 1).</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate (default: 0.0).</p>
</dd>
<dt><strong>**kwargs</strong></dt><dd><p>Additional arguments.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.GraphMLP.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.GraphMLP.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.GraphMLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.GraphMLP.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output tensor.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentityGAT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">IdentityGAT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentityGAT" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Graph Attention Network (GAT) with identity activation function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>hidden_channels</strong><span class="classifier">int</span></dt><dd><p>Number of hidden units.</p>
</dd>
<dt><strong>out_channels</strong><span class="classifier">int</span></dt><dd><p>Number of output features.</p>
</dd>
<dt><strong>num_layers</strong><span class="classifier">int</span></dt><dd><p>Number of layers.</p>
</dd>
<dt><strong>norm</strong><span class="classifier">torch.nn.Module</span></dt><dd><p>Normalization layer.</p>
</dd>
<dt><strong>heads</strong><span class="classifier">int, optional</span></dt><dd><p>Number of attention heads. Defaults to 1.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate. Defaults to 0.0.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentityGAT.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentityGAT.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentityGAT.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentityGAT.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input node features.</p>
</dd>
<dt><strong>edge_index</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Edge indices.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output node features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentityGCN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">IdentityGCN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentityGCN" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Graph Convolutional Network (GCN) with identity activation function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>hidden_channels</strong><span class="classifier">int</span></dt><dd><p>Number of hidden units.</p>
</dd>
<dt><strong>out_channels</strong><span class="classifier">int</span></dt><dd><p>Number of output features.</p>
</dd>
<dt><strong>num_layers</strong><span class="classifier">int</span></dt><dd><p>Number of layers.</p>
</dd>
<dt><strong>norm</strong><span class="classifier">torch.nn.Module</span></dt><dd><p>Normalization layer.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate. Defaults to 0.0.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentityGCN.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentityGCN.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentityGCN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentityGCN.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input node features.</p>
</dd>
<dt><strong>edge_index</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Edge indices.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output node features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentityGIN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">IdentityGIN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentityGIN" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Graph Isomorphism Network (GIN) with identity activation function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>hidden_channels</strong><span class="classifier">int</span></dt><dd><p>Number of hidden units.</p>
</dd>
<dt><strong>out_channels</strong><span class="classifier">int</span></dt><dd><p>Number of output features.</p>
</dd>
<dt><strong>num_layers</strong><span class="classifier">int</span></dt><dd><p>Number of layers.</p>
</dd>
<dt><strong>norm</strong><span class="classifier">torch.nn.Module</span></dt><dd><p>Normalization layer.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate. Defaults to 0.0.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentityGIN.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentityGIN.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentityGIN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentityGIN.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input node features.</p>
</dd>
<dt><strong>edge_index</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Edge indices.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output node features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentitySAGE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">IdentitySAGE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentitySAGE" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>GraphSAGE with identity activation function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>hidden_channels</strong><span class="classifier">int</span></dt><dd><p>Number of hidden units.</p>
</dd>
<dt><strong>out_channels</strong><span class="classifier">int</span></dt><dd><p>Number of output features.</p>
</dd>
<dt><strong>num_layers</strong><span class="classifier">int</span></dt><dd><p>Number of layers.</p>
</dd>
<dt><strong>norm</strong><span class="classifier">torch.nn.Module</span></dt><dd><p>Normalization layer.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate. Defaults to 0.0.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentitySAGE.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentitySAGE.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.IdentitySAGE.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.IdentitySAGE.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input node features.</p>
</dd>
<dt><strong>edge_index</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Edge indices.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output node features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.JumpLinkConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">JumpLinkConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'add'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.JumpLinkConv" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Class implementing the JumpLink Convolution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_features</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>out_features</strong><span class="classifier">int</span></dt><dd><p>Number of output features.</p>
</dd>
<dt><strong>mlp_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the MLP. Defaults to 2.</p>
</dd>
<dt><strong>aggr</strong><span class="classifier">str, optional</span></dt><dd><p>Aggregation method. Defaults to ‘add’.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Alpha value. Defaults to 0.5.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.JumpLinkConv.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'add'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.JumpLinkConv.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.JumpLinkConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vertex</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edges</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.JumpLinkConv.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">Tensor</span></dt><dd><p>Input features.</p>
</dd>
<dt><strong>vertex</strong><span class="classifier">LongTensor</span></dt><dd><p>Vertex index.</p>
</dd>
<dt><strong>edges</strong><span class="classifier">LongTensor</span></dt><dd><p>Edge index.</p>
</dd>
<dt><strong>X0</strong><span class="classifier">Tensor</span></dt><dd><p>Initial features.</p>
</dd>
<dt><strong>beta</strong><span class="classifier">float, optional</span></dt><dd><p>Beta value. Defaults to 1.0.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>Tensor</dt><dd><p>Output features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.JumpLinkConv.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.JumpLinkConv.reset_parameters" title="Link to this definition">#</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.MLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">MLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_act_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.MLP" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Multi-Layer Perceptron (MLP).</p>
<p>This class implements a multi-layer perceptron architecture with customizable
activation functions and normalization layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">int</span></dt><dd><p>The dimensionality of the input features.</p>
</dd>
<dt><strong>hidden_layers</strong><span class="classifier">int</span></dt><dd><p>The dimensionality of the hidden features.</p>
</dd>
<dt><strong>out_channels</strong><span class="classifier">int</span></dt><dd><p>The dimensionality of the output features.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>The dropout rate (default 0.25).</p>
</dd>
<dt><strong>norm</strong><span class="classifier">str, optional</span></dt><dd><p>The normalization layer to use (default None).</p>
</dd>
<dt><strong>norm_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Additional keyword arguments for the normalization layer (default None).</p>
</dd>
<dt><strong>act</strong><span class="classifier">str, optional</span></dt><dd><p>The activation function to use (default “relu”).</p>
</dd>
<dt><strong>act_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Additional keyword arguments for the activation function (default None).</p>
</dd>
<dt><strong>final_act</strong><span class="classifier">str, optional</span></dt><dd><p>The final activation function to use (default “sigmoid”).</p>
</dd>
<dt><strong>final_act_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Additional keyword arguments for the final activation function (default None).</p>
</dd>
<dt><strong>num_nodes</strong><span class="classifier">int, optional</span></dt><dd><p>The number of nodes in the input graph (default None).</p>
</dd>
<dt><strong>task_level</strong><span class="classifier">int, optional</span></dt><dd><p>The task level for the model (default None).</p>
</dd>
<dt><strong>**kwargs</strong></dt><dd><p>Additional keyword arguments.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.MLP.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_act_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.MLP.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.MLP.build_mlp_layers">
<span class="sig-name descname"><span class="pre">build_mlp_layers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.MLP.build_mlp_layers" title="Link to this definition">#</a></dt>
<dd><p>Build the MLP layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>nn.Sequential</dt><dd><p>The MLP layers.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.MLP.build_norm_layers">
<span class="sig-name descname"><span class="pre">build_norm_layers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.MLP.build_norm_layers" title="Link to this definition">#</a></dt>
<dd><p>Build the normalization layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>norm</strong><span class="classifier">str</span></dt><dd><p>The normalization layer to use.</p>
</dd>
<dt><strong>norm_kwargs</strong><span class="classifier">dict</span></dt><dd><p>Additional keyword arguments for the normalization layer.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>list</dt><dd><p>A list of normalization layers.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.MLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.MLP.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass through the MLP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor.</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int</span></dt><dd><p>Batch size.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output tensor.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.MeanDegConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">MeanDegConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp1_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp2_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp3_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.MeanDegConv" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Class implementing the Mean Degree Convolution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_features</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>out_features</strong><span class="classifier">int</span></dt><dd><p>Number of output features.</p>
</dd>
<dt><strong>init_features</strong><span class="classifier">int, optional</span></dt><dd><p>Number of initial features. Defaults to None.</p>
</dd>
<dt><strong>mlp1_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the first MLP. Defaults to 1.</p>
</dd>
<dt><strong>mlp2_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the second MLP. Defaults to 1.</p>
</dd>
<dt><strong>mlp3_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers in the third MLP. Defaults to 2.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.MeanDegConv.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp1_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp2_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp3_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.MeanDegConv.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.MeanDegConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vertex</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edges</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.MeanDegConv.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">Tensor</span></dt><dd><p>Input features.</p>
</dd>
<dt><strong>vertex</strong><span class="classifier">LongTensor</span></dt><dd><p>Vertex index.</p>
</dd>
<dt><strong>edges</strong><span class="classifier">LongTensor</span></dt><dd><p>Edge index.</p>
</dd>
<dt><strong>X0</strong><span class="classifier">Tensor</span></dt><dd><p>Initial features.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>Tensor</dt><dd><p>Output features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.MeanDegConv.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.MeanDegConv.reset_parameters" title="Link to this definition">#</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.Mlp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Mlp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hid_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.Mlp" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>MLP module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>input_dim</strong><span class="classifier">int</span></dt><dd><p>Input dimension.</p>
</dd>
<dt><strong>hid_dim</strong><span class="classifier">int</span></dt><dd><p>Hidden dimension.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float</span></dt><dd><p>Dropout rate.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.Mlp.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hid_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.Mlp.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.Mlp.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.Mlp.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output tensor.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.PlainMLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">PlainMLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.PlainMLP" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Class implementing a multi-layer perceptron without normalization.</p>
<p>Adapted from <a class="github reference external" href="https://github.com/CUAI/CorrectAndSmooth/blob/master/gen_models.py">CUAI/CorrectAndSmooth</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>hidden_channels</strong><span class="classifier">int</span></dt><dd><p>Number of hidden features.</p>
</dd>
<dt><strong>out_channels</strong><span class="classifier">int</span></dt><dd><p>Number of output features.</p>
</dd>
<dt><strong>num_layers</strong><span class="classifier">int</span></dt><dd><p>Number of layers.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate. Defaults to 0.5.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.PlainMLP.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.PlainMLP.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.PlainMLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.PlainMLP.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">Tensor</span></dt><dd><p>Input features.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>Tensor</dt><dd><p>Output features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.PlainMLP.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.PlainMLP.reset_parameters" title="Link to this definition">#</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.RedrawProjection">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">RedrawProjection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">redraw_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.RedrawProjection" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.14)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Helper class to handle redrawing of random projections in Performer attention.</p>
<p>This is crucial for maintaining the quality of the random feature approximation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>model</strong><span class="classifier">torch.nn.Module</span></dt><dd><p>The model containing PerformerAttention modules.</p>
</dd>
<dt><strong>redraw_interval</strong><span class="classifier">int or None, optional</span></dt><dd><p>Interval for redrawing random projections. If None, projections are not redrawn. Default is None.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.RedrawProjection.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">redraw_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.RedrawProjection.__init__" title="Link to this definition">#</a></dt>
<dd><dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.RedrawProjection.redraw_projections">
<span class="sig-name descname"><span class="pre">redraw_projections</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.RedrawProjection.redraw_projections" title="Link to this definition">#</a></dt>
<dd><p>Redraw random projections in PerformerAttention modules if needed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>None</dt><dd><p>None.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNCustom">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">SCCNNCustom</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels_all</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels_all</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_order</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sc_order</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNCustom" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>SCCNN implementation for complex classification.</p>
<p>Note: In this task, we can consider the output on any order of simplices for the
classification task, which of course can be amended by a readout layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels_all</strong><span class="classifier">tuple of int</span></dt><dd><p>Dimension of input features on (nodes, edges, faces).</p>
</dd>
<dt><strong>hidden_channels_all</strong><span class="classifier">tuple of int</span></dt><dd><p>Dimension of features of hidden layers on (nodes, edges, faces).</p>
</dd>
<dt><strong>conv_order</strong><span class="classifier">int</span></dt><dd><p>Order of convolutions, we consider the same order for all convolutions.</p>
</dd>
<dt><strong>sc_order</strong><span class="classifier">int</span></dt><dd><p>Order of simplicial complex.</p>
</dd>
<dt><strong>aggr_norm</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to normalize the aggregation (default: False).</p>
</dd>
<dt><strong>update_func</strong><span class="classifier">str, optional</span></dt><dd><p>Update function for the simplicial complex convolution (default: None).</p>
</dd>
<dt><strong>n_layers</strong><span class="classifier">int, optional</span></dt><dd><p>Number of layers (default: 2).</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNCustom.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels_all</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels_all</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_order</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sc_order</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNCustom.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNCustom.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_all</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">laplacian_all</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incidence_all</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNCustom.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x_all</strong><span class="classifier">tuple(tensors)</span></dt><dd><p>Tuple of feature tensors (node, edge, face).</p>
</dd>
<dt><strong>laplacian_all</strong><span class="classifier">tuple(tensors)</span></dt><dd><p>Tuple of Laplacian tensors (graph laplacian L0, down edge laplacian L1_d, upper edge laplacian L1_u, face laplacian L2).</p>
</dd>
<dt><strong>incidence_all</strong><span class="classifier">tuple(tensors)</span></dt><dd><p>Tuple of order 1 and 2 incidence matrices.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>tuple(tensors)</dt><dd><p>Tuple of final hidden state tensors (node, edge, face).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">SCCNNLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_order</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sc_order</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'xavier_normal'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNLayer" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Layer of a Simplicial Complex Convolutional Neural Network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">tuple of int</span></dt><dd><p>Dimensions of input features on nodes, edges, and faces.</p>
</dd>
<dt><strong>out_channels</strong><span class="classifier">tuple of int</span></dt><dd><p>Dimensions of output features on nodes, edges, and faces.</p>
</dd>
<dt><strong>conv_order</strong><span class="classifier">int</span></dt><dd><p>Convolution order of the simplicial filters.</p>
</dd>
<dt><strong>sc_order</strong><span class="classifier">int</span></dt><dd><p>SC order.</p>
</dd>
<dt><strong>aggr_norm</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to normalize the aggregated message by the neighborhood size (default: False).</p>
</dd>
<dt><strong>update_func</strong><span class="classifier">str, optional</span></dt><dd><p>Activation function used in aggregation layers (default: None).</p>
</dd>
<dt><strong>initialization</strong><span class="classifier">str, optional</span></dt><dd><p>Initialization method for the weights (default: “xavier_normal”).</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_order</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sc_order</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggr_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initialization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'xavier_normal'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNLayer.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNLayer.aggr_norm_func">
<span class="sig-name descname"><span class="pre">aggr_norm_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conv_operator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNLayer.aggr_norm_func" title="Link to this definition">#</a></dt>
<dd><p>Perform aggregation normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>conv_operator</strong><span class="classifier">torch.sparse</span></dt><dd><p>Convolution operator.</p>
</dd>
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Feature tensor.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Normalized feature tensor.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNLayer.chebyshev_conv">
<span class="sig-name descname"><span class="pre">chebyshev_conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conv_operator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_order</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNLayer.chebyshev_conv" title="Link to this definition">#</a></dt>
<dd><p>Perform Chebyshev convolution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>conv_operator</strong><span class="classifier">torch.sparse</span></dt><dd><p>Convolution operator.</p>
</dd>
<dt><strong>conv_order</strong><span class="classifier">int</span></dt><dd><p>Order of the convolution.</p>
</dd>
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Feature tensor.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output tensor.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNLayer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_all</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">laplacian_all</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">incidence_all</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNLayer.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x_all</strong><span class="classifier">tuple of tensors</span></dt><dd><p>Tuple of input feature tensors (node, edge, face).</p>
</dd>
<dt><strong>laplacian_all</strong><span class="classifier">tuple of tensors</span></dt><dd><p>Tuple of Laplacian tensors (graph laplacian L0, down edge laplacian L1_d, upper edge laplacian L1_u, face laplacian L2).</p>
</dd>
<dt><strong>incidence_all</strong><span class="classifier">tuple of tensors</span></dt><dd><p>Tuple of order 1 and 2 incidence matrices.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Output tensor for each 0-cell.</p>
</dd>
<dt>torch.Tensor</dt><dd><p>Output tensor for each 1-cell.</p>
</dd>
<dt>torch.Tensor</dt><dd><p>Output tensor for each 2-cell.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNLayer.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.414</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNLayer.reset_parameters" title="Link to this definition">#</a></dt>
<dd><p>Reset learnable parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>gain</strong><span class="classifier">float</span></dt><dd><p>Gain for the weight initialization.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.SCCNNLayer.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.SCCNNLayer.update" title="Link to this definition">#</a></dt>
<dd><p>Update embeddings on each cell (step 4).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Updated tensor.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">TopoTune</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">GNN</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neighborhoods</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_edge_attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Tunes a GNN model using higher-order relations.</p>
<p>This class takes a GNN and its kwargs as inputs, and tunes it with specified additional relations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>GNN</strong><span class="classifier">torch.nn.Module, a class not an object</span></dt><dd><p>The GNN class to use. ex: GAT, GCN.</p>
</dd>
<dt><strong>neighborhoods</strong><span class="classifier">list of lists</span></dt><dd><p>The neighborhoods of interest.</p>
</dd>
<dt><strong>layers</strong><span class="classifier">int</span></dt><dd><p>The number of layers to use. Each layer contains one GNN.</p>
</dd>
<dt><strong>use_edge_attr</strong><span class="classifier">bool</span></dt><dd><p>Whether to use edge attributes.</p>
</dd>
<dt><strong>activation</strong><span class="classifier">str</span></dt><dd><p>The activation function to use. ex: ‘relu’, ‘tanh’, ‘sigmoid’.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">GNN</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neighborhoods</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_edge_attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune.aggregate_inter_nbhd">
<span class="sig-name descname"><span class="pre">aggregate_inter_nbhd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_out_per_route</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune.aggregate_inter_nbhd" title="Link to this definition">#</a></dt>
<dd><p>Aggregate the outputs of the GNN for each rank.</p>
<p>While the GNN takes care of intra-nbhd aggregation,
this will take care of inter-nbhd aggregation.
Default: sum.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x_out_per_route</strong><span class="classifier">dict</span></dt><dd><p>The outputs of the GNN for each route.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dict</dt><dd><p>The aggregated outputs of the GNN for each rank.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>batch</strong><span class="classifier">Complex or ComplexBatch(Complex)</span></dt><dd><p>The input data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dict</dt><dd><p>The output hidden states of the model per rank.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune.generate_membership_vectors">
<span class="sig-name descname"><span class="pre">generate_membership_vectors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune.generate_membership_vectors" title="Link to this definition">#</a></dt>
<dd><p>Generate membership vectors based on batch.cell_statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>batch</strong><span class="classifier">torch_geometric.data.Data</span></dt><dd><p>Batch object containing the batched domain data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dict</dt><dd><p>The batch membership of the graphs per rank.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune.get_nbhd_cache">
<span class="sig-name descname"><span class="pre">get_nbhd_cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune.get_nbhd_cache" title="Link to this definition">#</a></dt>
<dd><p>Cache the nbhd information into a dict for the complex at hand.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>The parameters of the batch, containing the complex.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dict</dt><dd><p>The neighborhood cache.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune.interrank_expand">
<span class="sig-name descname"><span class="pre">interrank_expand</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_rank</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dst_rank</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nbhd_cache</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">membership</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune.interrank_expand" title="Link to this definition">#</a></dt>
<dd><p>Expand the complex into an interrank Hasse graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>The parameters of the batch, containting the complex.</p>
</dd>
<dt><strong>src_rank</strong><span class="classifier">int</span></dt><dd><p>The source rank.</p>
</dd>
<dt><strong>dst_rank</strong><span class="classifier">int</span></dt><dd><p>The destination rank.</p>
</dd>
<dt><strong>nbhd_cache</strong><span class="classifier">dict</span></dt><dd><p>The neighborhood cache containing the expanded boundary index and edge attributes.</p>
</dd>
<dt><strong>membership</strong><span class="classifier">dict</span></dt><dd><p>The batch membership of the graphs per rank.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch_geometric.data.Data</dt><dd><p>The expanded batch of interrank Hasse graphs for this route.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune.interrank_gnn_forward">
<span class="sig-name descname"><span class="pre">interrank_gnn_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_route</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">route_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_dst_cells</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune.interrank_gnn_forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass of the GNN (one layer) for an interrank Hasse graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>batch_route</strong><span class="classifier">torch_geometric.data.Data</span></dt><dd><p>The batch of interrank Hasse graphs for this route.</p>
</dd>
<dt><strong>layer_idx</strong><span class="classifier">int</span></dt><dd><p>The index of the layer.</p>
</dd>
<dt><strong>route_index</strong><span class="classifier">int</span></dt><dd><p>The index of the route.</p>
</dd>
<dt><strong>n_dst_cells</strong><span class="classifier">int</span></dt><dd><p>The number of destination cells in the whole batch.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.tensor</dt><dd><p>The output of the GNN (updated features).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune.intrarank_expand">
<span class="sig-name descname"><span class="pre">intrarank_expand</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_rank</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nbhd</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune.intrarank_expand" title="Link to this definition">#</a></dt>
<dd><p>Expand the complex into an intrarank Hasse graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>The parameters of the batch, containting the complex.</p>
</dd>
<dt><strong>src_rank</strong><span class="classifier">int</span></dt><dd><p>The source rank.</p>
</dd>
<dt><strong>nbhd</strong><span class="classifier">str</span></dt><dd><p>The neighborhood to use.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch_geometric.data.Data</dt><dd><p>The expanded batch of intrarank Hasse graphs for this route.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune.intrarank_gnn_forward">
<span class="sig-name descname"><span class="pre">intrarank_gnn_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_route</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">route_index</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune.intrarank_gnn_forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass of the GNN (one layer) for an intrarank Hasse graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>batch_route</strong><span class="classifier">torch_geometric.data.Data</span></dt><dd><p>The batch of intrarank Hasse graphs for this route.</p>
</dd>
<dt><strong>layer_idx</strong><span class="classifier">int</span></dt><dd><p>The index of the TopoTune layer.</p>
</dd>
<dt><strong>route_index</strong><span class="classifier">int</span></dt><dd><p>The index of the route.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.tensor</dt><dd><p>The output of the GNN (updated features).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune_OneHasse">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">TopoTune_OneHasse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">GNN</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neighborhoods</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_edge_attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune_OneHasse" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Tunes a GNN model using higher-order relations.</p>
<p>This class takes a GNN and its kwargs as inputs, and tunes it with specified additional relations.
Unlike the case of TopoTune, this class expects a single Hasse graph as input, where all
higher-order neighborhoods are represented as a single adjacency matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>GNN</strong><span class="classifier">torch.nn.Module, a class not an object</span></dt><dd><p>The GNN class to use. ex: GAT, GCN.</p>
</dd>
<dt><strong>neighborhoods</strong><span class="classifier">list of lists</span></dt><dd><p>The neighborhoods of interest.</p>
</dd>
<dt><strong>layers</strong><span class="classifier">int</span></dt><dd><p>The number of layers to use. Each layer contains one GNN.</p>
</dd>
<dt><strong>use_edge_attr</strong><span class="classifier">bool</span></dt><dd><p>Whether to use edge attributes.</p>
</dd>
<dt><strong>activation</strong><span class="classifier">str</span></dt><dd><p>The activation function to use. ex: ‘relu’, ‘tanh’, ‘sigmoid’.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune_OneHasse.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">GNN</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neighborhoods</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_edge_attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune_OneHasse.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune_OneHasse.aggregate_inter_nbhd">
<span class="sig-name descname"><span class="pre">aggregate_inter_nbhd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_out</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune_OneHasse.aggregate_inter_nbhd" title="Link to this definition">#</a></dt>
<dd><p>Aggregate the outputs of the GNN for each rank.</p>
<p>While the GNN takes care of intra-nbhd aggregation,
this will take care of inter-nbhd aggregation.
Default: sum.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x_out</strong><span class="classifier">torch.tensor</span></dt><dd><p>The output of the GNN, concatenated features of each rank.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dict</dt><dd><p>The aggregated outputs of the GNN for each rank.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune_OneHasse.all_nbhds_expand">
<span class="sig-name descname"><span class="pre">all_nbhds_expand</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">membership</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune_OneHasse.all_nbhds_expand" title="Link to this definition">#</a></dt>
<dd><p>Expand the complex into a single Hasse graph which contains all ranks and all nbhd.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>The parameters of the batch, containing the complex.</p>
</dd>
<dt><strong>membership</strong><span class="classifier">dict</span></dt><dd><p>The batch membership of the graphs per rank.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch_geometric.data.Data</dt><dd><p>The expanded Hasse graph.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune_OneHasse.all_nbhds_gnn_forward">
<span class="sig-name descname"><span class="pre">all_nbhds_gnn_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_route</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_idx</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune_OneHasse.all_nbhds_gnn_forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass of the GNN (one layer) for an intrarank Hasse graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>batch_route</strong><span class="classifier">torch_geometric.data.Data</span></dt><dd><p>The batch of intrarank Hasse graphs for this route.</p>
</dd>
<dt><strong>layer_idx</strong><span class="classifier">int</span></dt><dd><p>The index of the TopoTune layer.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.tensor</dt><dd><p>The output of the GNN (updated features).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune_OneHasse.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune_OneHasse.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>batch</strong><span class="classifier">Complex or ComplexBatch(Complex)</span></dt><dd><p>The input data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dict</dt><dd><p>The output hidden states of the model per rank.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.TopoTune_OneHasse.generate_membership_vectors">
<span class="sig-name descname"><span class="pre">generate_membership_vectors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.TopoTune_OneHasse.generate_membership_vectors" title="Link to this definition">#</a></dt>
<dd><p>Generate membership vectors based on batch.cell_statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>batch</strong><span class="classifier">torch_geometric.data.Data</span></dt><dd><p>Batch object containing the batched domain data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dict</dt><dd><p>The batch membership of the graphs per rank.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="topobench.nn.backbones.customMLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">customMLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">InputNorm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.customMLP" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Class implementing a multi-layer perceptron.</p>
<p>Adapted from <a class="github reference external" href="https://github.com/CUAI/CorrectAndSmooth/blob/master/gen_models.py">CUAI/CorrectAndSmooth</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_channels</strong><span class="classifier">int</span></dt><dd><p>Number of input features.</p>
</dd>
<dt><strong>hidden_channels</strong><span class="classifier">int</span></dt><dd><p>Number of hidden features.</p>
</dd>
<dt><strong>out_channels</strong><span class="classifier">int</span></dt><dd><p>Number of output features.</p>
</dd>
<dt><strong>num_layers</strong><span class="classifier">int</span></dt><dd><p>Number of layers.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier">float, optional</span></dt><dd><p>Dropout rate. Defaults to 0.5.</p>
</dd>
<dt><strong>Normalization</strong><span class="classifier">str, optiona</span></dt><dd><p>Normalization method. Defaults to ‘bn’.</p>
</dd>
<dt><strong>InputNorm</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to normalize input features. Defaults to False.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.customMLP.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">InputNorm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.customMLP.__init__" title="Link to this definition">#</a></dt>
<dd><p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.customMLP.flops">
<span class="sig-name descname"><span class="pre">flops</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.customMLP.flops" title="Link to this definition">#</a></dt>
<dd><p>Calculate FLOPs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">Tensor</span></dt><dd><p>Input features.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>int</dt><dd><p>FLOPs.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.customMLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.customMLP.forward" title="Link to this definition">#</a></dt>
<dd><p>Forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">Tensor</span></dt><dd><p>Input features.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>Tensor</dt><dd><p>Output features.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="topobench.nn.backbones.customMLP.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#topobench.nn.backbones.customMLP.reset_parameters" title="Link to this definition">#</a></dt>
<dd><p>Reset parameters.</p>
</dd></dl>

</dd></dl>

<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Link to this heading">#</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="topobench.nn.backbones.cell.html">topobench.nn.backbones.cell package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.cell.html#topobench.nn.backbones.cell.CCCN"><code class="docutils literal notranslate"><span class="pre">CCCN</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.cell.html#topobench.nn.backbones.cell.CCCN.__init__"><code class="docutils literal notranslate"><span class="pre">CCCN.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.cell.html#topobench.nn.backbones.cell.CCCN.forward"><code class="docutils literal notranslate"><span class="pre">CCCN.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.cell.html#topobench.nn.backbones.cell.CW"><code class="docutils literal notranslate"><span class="pre">CW</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.cell.html#topobench.nn.backbones.cell.CW.__init__"><code class="docutils literal notranslate"><span class="pre">CW.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.cell.html#topobench.nn.backbones.cell.CW.forward"><code class="docutils literal notranslate"><span class="pre">CW.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.cell.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.cell.cccn.html">topobench.nn.backbones.cell.cccn module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.cell.cccn.html#topobench.nn.backbones.cell.cccn.CCCN"><code class="docutils literal notranslate"><span class="pre">CCCN</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.cell.cccn.html#topobench.nn.backbones.cell.cccn.CW"><code class="docutils literal notranslate"><span class="pre">CW</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.cell.cccn.html#topobench.nn.backbones.cell.cccn.GCNConv"><code class="docutils literal notranslate"><span class="pre">GCNConv</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html">topobench.nn.backbones.combinatorial package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune"><code class="docutils literal notranslate"><span class="pre">TopoTune</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune.__init__"><code class="docutils literal notranslate"><span class="pre">TopoTune.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune.aggregate_inter_nbhd"><code class="docutils literal notranslate"><span class="pre">TopoTune.aggregate_inter_nbhd()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune.forward"><code class="docutils literal notranslate"><span class="pre">TopoTune.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune.generate_membership_vectors"><code class="docutils literal notranslate"><span class="pre">TopoTune.generate_membership_vectors()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune.get_nbhd_cache"><code class="docutils literal notranslate"><span class="pre">TopoTune.get_nbhd_cache()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune.interrank_expand"><code class="docutils literal notranslate"><span class="pre">TopoTune.interrank_expand()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune.interrank_gnn_forward"><code class="docutils literal notranslate"><span class="pre">TopoTune.interrank_gnn_forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune.intrarank_expand"><code class="docutils literal notranslate"><span class="pre">TopoTune.intrarank_expand()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune.intrarank_gnn_forward"><code class="docutils literal notranslate"><span class="pre">TopoTune.intrarank_gnn_forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune_OneHasse"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune_OneHasse.__init__"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune_OneHasse.aggregate_inter_nbhd"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.aggregate_inter_nbhd()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune_OneHasse.all_nbhds_expand"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.all_nbhds_expand()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune_OneHasse.all_nbhds_gnn_forward"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.all_nbhds_gnn_forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune_OneHasse.forward"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#topobench.nn.backbones.combinatorial.TopoTune_OneHasse.generate_membership_vectors"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.generate_membership_vectors()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.combinatorial.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn.html">topobench.nn.backbones.combinatorial.gccn module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn.html#topobench.nn.backbones.combinatorial.gccn.Data"><code class="docutils literal notranslate"><span class="pre">Data</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn.html#topobench.nn.backbones.combinatorial.gccn.TopoTune"><code class="docutils literal notranslate"><span class="pre">TopoTune</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn.html#topobench.nn.backbones.combinatorial.gccn.get_activation"><code class="docutils literal notranslate"><span class="pre">get_activation()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn.html#topobench.nn.backbones.combinatorial.gccn.get_routes_from_neighborhoods"><code class="docutils literal notranslate"><span class="pre">get_routes_from_neighborhoods()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn.html#topobench.nn.backbones.combinatorial.gccn.interrank_boundary_index"><code class="docutils literal notranslate"><span class="pre">interrank_boundary_index()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn_onehasse.html">topobench.nn.backbones.combinatorial.gccn_onehasse module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn_onehasse.html#topobench.nn.backbones.combinatorial.gccn_onehasse.Data"><code class="docutils literal notranslate"><span class="pre">Data</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn_onehasse.html#topobench.nn.backbones.combinatorial.gccn_onehasse.TopoTune_OneHasse"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn_onehasse.html#topobench.nn.backbones.combinatorial.gccn_onehasse.get_activation"><code class="docutils literal notranslate"><span class="pre">get_activation()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.combinatorial.gccn_onehasse.html#topobench.nn.backbones.combinatorial.gccn_onehasse.get_routes_from_neighborhoods"><code class="docutils literal notranslate"><span class="pre">get_routes_from_neighborhoods()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topobench.nn.backbones.graph.html">topobench.nn.backbones.graph package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.GPSEncoder"><code class="docutils literal notranslate"><span class="pre">GPSEncoder</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.GPSEncoder.__init__"><code class="docutils literal notranslate"><span class="pre">GPSEncoder.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.GPSEncoder.forward"><code class="docutils literal notranslate"><span class="pre">GPSEncoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.GraphMLP"><code class="docutils literal notranslate"><span class="pre">GraphMLP</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.GraphMLP.__init__"><code class="docutils literal notranslate"><span class="pre">GraphMLP.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.GraphMLP.forward"><code class="docutils literal notranslate"><span class="pre">GraphMLP.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentityGAT"><code class="docutils literal notranslate"><span class="pre">IdentityGAT</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentityGAT.__init__"><code class="docutils literal notranslate"><span class="pre">IdentityGAT.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentityGAT.forward"><code class="docutils literal notranslate"><span class="pre">IdentityGAT.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentityGCN"><code class="docutils literal notranslate"><span class="pre">IdentityGCN</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentityGCN.__init__"><code class="docutils literal notranslate"><span class="pre">IdentityGCN.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentityGCN.forward"><code class="docutils literal notranslate"><span class="pre">IdentityGCN.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentityGIN"><code class="docutils literal notranslate"><span class="pre">IdentityGIN</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentityGIN.__init__"><code class="docutils literal notranslate"><span class="pre">IdentityGIN.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentityGIN.forward"><code class="docutils literal notranslate"><span class="pre">IdentityGIN.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentitySAGE"><code class="docutils literal notranslate"><span class="pre">IdentitySAGE</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentitySAGE.__init__"><code class="docutils literal notranslate"><span class="pre">IdentitySAGE.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.IdentitySAGE.forward"><code class="docutils literal notranslate"><span class="pre">IdentitySAGE.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.Mlp"><code class="docutils literal notranslate"><span class="pre">Mlp</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.Mlp.__init__"><code class="docutils literal notranslate"><span class="pre">Mlp.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.Mlp.forward"><code class="docutils literal notranslate"><span class="pre">Mlp.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.RedrawProjection"><code class="docutils literal notranslate"><span class="pre">RedrawProjection</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.RedrawProjection.__init__"><code class="docutils literal notranslate"><span class="pre">RedrawProjection.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.html#topobench.nn.backbones.graph.RedrawProjection.redraw_projections"><code class="docutils literal notranslate"><span class="pre">RedrawProjection.redraw_projections()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.graph.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.gps.html">topobench.nn.backbones.graph.gps module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.gps.html#topobench.nn.backbones.graph.gps.Any"><code class="docutils literal notranslate"><span class="pre">Any</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.gps.html#topobench.nn.backbones.graph.gps.GINConv"><code class="docutils literal notranslate"><span class="pre">GINConv</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.gps.html#topobench.nn.backbones.graph.gps.GPSConv"><code class="docutils literal notranslate"><span class="pre">GPSConv</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.gps.html#topobench.nn.backbones.graph.gps.GPSEncoder"><code class="docutils literal notranslate"><span class="pre">GPSEncoder</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.gps.html#topobench.nn.backbones.graph.gps.PNAConv"><code class="docutils literal notranslate"><span class="pre">PNAConv</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.gps.html#topobench.nn.backbones.graph.gps.PerformerAttention"><code class="docutils literal notranslate"><span class="pre">PerformerAttention</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.gps.html#topobench.nn.backbones.graph.gps.RedrawProjection"><code class="docutils literal notranslate"><span class="pre">RedrawProjection</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.graph_mlp.html">topobench.nn.backbones.graph.graph_mlp module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.graph_mlp.html#topobench.nn.backbones.graph.graph_mlp.Dropout"><code class="docutils literal notranslate"><span class="pre">Dropout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.graph_mlp.html#topobench.nn.backbones.graph.graph_mlp.GraphMLP"><code class="docutils literal notranslate"><span class="pre">GraphMLP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.graph_mlp.html#topobench.nn.backbones.graph.graph_mlp.LayerNorm"><code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.graph_mlp.html#topobench.nn.backbones.graph.graph_mlp.Linear"><code class="docutils literal notranslate"><span class="pre">Linear</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.graph_mlp.html#topobench.nn.backbones.graph.graph_mlp.Mlp"><code class="docutils literal notranslate"><span class="pre">Mlp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.graph_mlp.html#topobench.nn.backbones.graph.graph_mlp.get_feature_dis"><code class="docutils literal notranslate"><span class="pre">get_feature_dis()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.graph.identity_gnn.html">topobench.nn.backbones.graph.identity_gnn module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.identity_gnn.html#topobench.nn.backbones.graph.identity_gnn.GAT"><code class="docutils literal notranslate"><span class="pre">GAT</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.identity_gnn.html#topobench.nn.backbones.graph.identity_gnn.GCN"><code class="docutils literal notranslate"><span class="pre">GCN</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.identity_gnn.html#topobench.nn.backbones.graph.identity_gnn.GIN"><code class="docutils literal notranslate"><span class="pre">GIN</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.identity_gnn.html#topobench.nn.backbones.graph.identity_gnn.GraphSAGE"><code class="docutils literal notranslate"><span class="pre">GraphSAGE</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.identity_gnn.html#topobench.nn.backbones.graph.identity_gnn.IdentityGAT"><code class="docutils literal notranslate"><span class="pre">IdentityGAT</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.identity_gnn.html#topobench.nn.backbones.graph.identity_gnn.IdentityGCN"><code class="docutils literal notranslate"><span class="pre">IdentityGCN</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.identity_gnn.html#topobench.nn.backbones.graph.identity_gnn.IdentityGIN"><code class="docutils literal notranslate"><span class="pre">IdentityGIN</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.graph.identity_gnn.html#topobench.nn.backbones.graph.identity_gnn.IdentitySAGE"><code class="docutils literal notranslate"><span class="pre">IdentitySAGE</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html">topobench.nn.backbones.hypergraph package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.EDGNN"><code class="docutils literal notranslate"><span class="pre">EDGNN</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.EDGNN.__init__"><code class="docutils literal notranslate"><span class="pre">EDGNN.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.EDGNN.forward"><code class="docutils literal notranslate"><span class="pre">EDGNN.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.EDGNN.reset_parameters"><code class="docutils literal notranslate"><span class="pre">EDGNN.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.EquivSetConv"><code class="docutils literal notranslate"><span class="pre">EquivSetConv</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.EquivSetConv.__init__"><code class="docutils literal notranslate"><span class="pre">EquivSetConv.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.EquivSetConv.forward"><code class="docutils literal notranslate"><span class="pre">EquivSetConv.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.EquivSetConv.reset_parameters"><code class="docutils literal notranslate"><span class="pre">EquivSetConv.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.JumpLinkConv"><code class="docutils literal notranslate"><span class="pre">JumpLinkConv</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.JumpLinkConv.__init__"><code class="docutils literal notranslate"><span class="pre">JumpLinkConv.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.JumpLinkConv.forward"><code class="docutils literal notranslate"><span class="pre">JumpLinkConv.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.JumpLinkConv.reset_parameters"><code class="docutils literal notranslate"><span class="pre">JumpLinkConv.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.MeanDegConv"><code class="docutils literal notranslate"><span class="pre">MeanDegConv</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.MeanDegConv.__init__"><code class="docutils literal notranslate"><span class="pre">MeanDegConv.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.MeanDegConv.forward"><code class="docutils literal notranslate"><span class="pre">MeanDegConv.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.MeanDegConv.reset_parameters"><code class="docutils literal notranslate"><span class="pre">MeanDegConv.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.PlainMLP"><code class="docutils literal notranslate"><span class="pre">PlainMLP</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.PlainMLP.__init__"><code class="docutils literal notranslate"><span class="pre">PlainMLP.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.PlainMLP.forward"><code class="docutils literal notranslate"><span class="pre">PlainMLP.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.PlainMLP.reset_parameters"><code class="docutils literal notranslate"><span class="pre">PlainMLP.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.customMLP"><code class="docutils literal notranslate"><span class="pre">customMLP</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.customMLP.__init__"><code class="docutils literal notranslate"><span class="pre">customMLP.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.customMLP.flops"><code class="docutils literal notranslate"><span class="pre">customMLP.flops()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.customMLP.forward"><code class="docutils literal notranslate"><span class="pre">customMLP.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#topobench.nn.backbones.hypergraph.customMLP.reset_parameters"><code class="docutils literal notranslate"><span class="pre">customMLP.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.hypergraph.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.hypergraph.edgnn.html">topobench.nn.backbones.hypergraph.edgnn module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.hypergraph.edgnn.html#topobench.nn.backbones.hypergraph.edgnn.EDGNN"><code class="docutils literal notranslate"><span class="pre">EDGNN</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.hypergraph.edgnn.html#topobench.nn.backbones.hypergraph.edgnn.EquivSetConv"><code class="docutils literal notranslate"><span class="pre">EquivSetConv</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.hypergraph.edgnn.html#topobench.nn.backbones.hypergraph.edgnn.JumpLinkConv"><code class="docutils literal notranslate"><span class="pre">JumpLinkConv</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.hypergraph.edgnn.html#topobench.nn.backbones.hypergraph.edgnn.MeanDegConv"><code class="docutils literal notranslate"><span class="pre">MeanDegConv</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.hypergraph.edgnn.html#topobench.nn.backbones.hypergraph.edgnn.PlainMLP"><code class="docutils literal notranslate"><span class="pre">PlainMLP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.hypergraph.edgnn.html#topobench.nn.backbones.hypergraph.edgnn.customMLP"><code class="docutils literal notranslate"><span class="pre">customMLP</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topobench.nn.backbones.non_relational.html">topobench.nn.backbones.non_relational package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.non_relational.html#topobench.nn.backbones.non_relational.MLP"><code class="docutils literal notranslate"><span class="pre">MLP</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.non_relational.html#topobench.nn.backbones.non_relational.MLP.__init__"><code class="docutils literal notranslate"><span class="pre">MLP.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.non_relational.html#topobench.nn.backbones.non_relational.MLP.build_mlp_layers"><code class="docutils literal notranslate"><span class="pre">MLP.build_mlp_layers()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.non_relational.html#topobench.nn.backbones.non_relational.MLP.build_norm_layers"><code class="docutils literal notranslate"><span class="pre">MLP.build_norm_layers()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.non_relational.html#topobench.nn.backbones.non_relational.MLP.forward"><code class="docutils literal notranslate"><span class="pre">MLP.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.non_relational.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.non_relational.mlp.html">topobench.nn.backbones.non_relational.mlp module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.non_relational.mlp.html#topobench.nn.backbones.non_relational.mlp.MLP"><code class="docutils literal notranslate"><span class="pre">MLP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.non_relational.mlp.html#topobench.nn.backbones.non_relational.mlp.activation_resolver"><code class="docutils literal notranslate"><span class="pre">activation_resolver()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.non_relational.mlp.html#topobench.nn.backbones.non_relational.mlp.normalization_resolver"><code class="docutils literal notranslate"><span class="pre">normalization_resolver()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topobench.nn.backbones.simplicial.html">topobench.nn.backbones.simplicial package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNCustom"><code class="docutils literal notranslate"><span class="pre">SCCNNCustom</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNCustom.__init__"><code class="docutils literal notranslate"><span class="pre">SCCNNCustom.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNCustom.forward"><code class="docutils literal notranslate"><span class="pre">SCCNNCustom.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNLayer"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNLayer.__init__"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNLayer.aggr_norm_func"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.aggr_norm_func()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNLayer.chebyshev_conv"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.chebyshev_conv()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNLayer.forward"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNLayer.reset_parameters"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.reset_parameters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#topobench.nn.backbones.simplicial.SCCNNLayer.update"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.update()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topobench.nn.backbones.simplicial.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topobench.nn.backbones.simplicial.sccnn.html">topobench.nn.backbones.simplicial.sccnn module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.simplicial.sccnn.html#topobench.nn.backbones.simplicial.sccnn.Parameter"><code class="docutils literal notranslate"><span class="pre">Parameter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.simplicial.sccnn.html#topobench.nn.backbones.simplicial.sccnn.SCCNNCustom"><code class="docutils literal notranslate"><span class="pre">SCCNNCustom</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="topobench.nn.backbones.simplicial.sccnn.html#topobench.nn.backbones.simplicial.sccnn.SCCNNLayer"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="topobench.nn.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">topobench.nn package</p>
      </div>
    </a>
    <a class="right-next"
       href="topobench.nn.backbones.cell.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">topobench.nn.backbones.cell package</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.CCCN"><code class="docutils literal notranslate"><span class="pre">CCCN</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.CCCN.__init__"><code class="docutils literal notranslate"><span class="pre">CCCN.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.CCCN.forward"><code class="docutils literal notranslate"><span class="pre">CCCN.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.CW"><code class="docutils literal notranslate"><span class="pre">CW</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.CW.__init__"><code class="docutils literal notranslate"><span class="pre">CW.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.CW.forward"><code class="docutils literal notranslate"><span class="pre">CW.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.EDGNN"><code class="docutils literal notranslate"><span class="pre">EDGNN</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.EDGNN.__init__"><code class="docutils literal notranslate"><span class="pre">EDGNN.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.EDGNN.forward"><code class="docutils literal notranslate"><span class="pre">EDGNN.forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.EDGNN.reset_parameters"><code class="docutils literal notranslate"><span class="pre">EDGNN.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.EquivSetConv"><code class="docutils literal notranslate"><span class="pre">EquivSetConv</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.EquivSetConv.__init__"><code class="docutils literal notranslate"><span class="pre">EquivSetConv.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.EquivSetConv.forward"><code class="docutils literal notranslate"><span class="pre">EquivSetConv.forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.EquivSetConv.reset_parameters"><code class="docutils literal notranslate"><span class="pre">EquivSetConv.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.GPSEncoder"><code class="docutils literal notranslate"><span class="pre">GPSEncoder</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.GPSEncoder.__init__"><code class="docutils literal notranslate"><span class="pre">GPSEncoder.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.GPSEncoder.forward"><code class="docutils literal notranslate"><span class="pre">GPSEncoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.GraphMLP"><code class="docutils literal notranslate"><span class="pre">GraphMLP</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.GraphMLP.__init__"><code class="docutils literal notranslate"><span class="pre">GraphMLP.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.GraphMLP.forward"><code class="docutils literal notranslate"><span class="pre">GraphMLP.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentityGAT"><code class="docutils literal notranslate"><span class="pre">IdentityGAT</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentityGAT.__init__"><code class="docutils literal notranslate"><span class="pre">IdentityGAT.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentityGAT.forward"><code class="docutils literal notranslate"><span class="pre">IdentityGAT.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentityGCN"><code class="docutils literal notranslate"><span class="pre">IdentityGCN</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentityGCN.__init__"><code class="docutils literal notranslate"><span class="pre">IdentityGCN.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentityGCN.forward"><code class="docutils literal notranslate"><span class="pre">IdentityGCN.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentityGIN"><code class="docutils literal notranslate"><span class="pre">IdentityGIN</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentityGIN.__init__"><code class="docutils literal notranslate"><span class="pre">IdentityGIN.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentityGIN.forward"><code class="docutils literal notranslate"><span class="pre">IdentityGIN.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentitySAGE"><code class="docutils literal notranslate"><span class="pre">IdentitySAGE</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentitySAGE.__init__"><code class="docutils literal notranslate"><span class="pre">IdentitySAGE.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.IdentitySAGE.forward"><code class="docutils literal notranslate"><span class="pre">IdentitySAGE.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.JumpLinkConv"><code class="docutils literal notranslate"><span class="pre">JumpLinkConv</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.JumpLinkConv.__init__"><code class="docutils literal notranslate"><span class="pre">JumpLinkConv.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.JumpLinkConv.forward"><code class="docutils literal notranslate"><span class="pre">JumpLinkConv.forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.JumpLinkConv.reset_parameters"><code class="docutils literal notranslate"><span class="pre">JumpLinkConv.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.MLP"><code class="docutils literal notranslate"><span class="pre">MLP</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.MLP.__init__"><code class="docutils literal notranslate"><span class="pre">MLP.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.MLP.build_mlp_layers"><code class="docutils literal notranslate"><span class="pre">MLP.build_mlp_layers()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.MLP.build_norm_layers"><code class="docutils literal notranslate"><span class="pre">MLP.build_norm_layers()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.MLP.forward"><code class="docutils literal notranslate"><span class="pre">MLP.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.MeanDegConv"><code class="docutils literal notranslate"><span class="pre">MeanDegConv</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.MeanDegConv.__init__"><code class="docutils literal notranslate"><span class="pre">MeanDegConv.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.MeanDegConv.forward"><code class="docutils literal notranslate"><span class="pre">MeanDegConv.forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.MeanDegConv.reset_parameters"><code class="docutils literal notranslate"><span class="pre">MeanDegConv.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.Mlp"><code class="docutils literal notranslate"><span class="pre">Mlp</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.Mlp.__init__"><code class="docutils literal notranslate"><span class="pre">Mlp.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.Mlp.forward"><code class="docutils literal notranslate"><span class="pre">Mlp.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.PlainMLP"><code class="docutils literal notranslate"><span class="pre">PlainMLP</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.PlainMLP.__init__"><code class="docutils literal notranslate"><span class="pre">PlainMLP.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.PlainMLP.forward"><code class="docutils literal notranslate"><span class="pre">PlainMLP.forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.PlainMLP.reset_parameters"><code class="docutils literal notranslate"><span class="pre">PlainMLP.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.RedrawProjection"><code class="docutils literal notranslate"><span class="pre">RedrawProjection</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.RedrawProjection.__init__"><code class="docutils literal notranslate"><span class="pre">RedrawProjection.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.RedrawProjection.redraw_projections"><code class="docutils literal notranslate"><span class="pre">RedrawProjection.redraw_projections()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNCustom"><code class="docutils literal notranslate"><span class="pre">SCCNNCustom</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNCustom.__init__"><code class="docutils literal notranslate"><span class="pre">SCCNNCustom.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNCustom.forward"><code class="docutils literal notranslate"><span class="pre">SCCNNCustom.forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNLayer"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNLayer.__init__"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNLayer.aggr_norm_func"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.aggr_norm_func()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNLayer.chebyshev_conv"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.chebyshev_conv()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNLayer.forward"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNLayer.reset_parameters"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.reset_parameters()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.SCCNNLayer.update"><code class="docutils literal notranslate"><span class="pre">SCCNNLayer.update()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune"><code class="docutils literal notranslate"><span class="pre">TopoTune</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune.__init__"><code class="docutils literal notranslate"><span class="pre">TopoTune.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune.aggregate_inter_nbhd"><code class="docutils literal notranslate"><span class="pre">TopoTune.aggregate_inter_nbhd()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune.forward"><code class="docutils literal notranslate"><span class="pre">TopoTune.forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune.generate_membership_vectors"><code class="docutils literal notranslate"><span class="pre">TopoTune.generate_membership_vectors()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune.get_nbhd_cache"><code class="docutils literal notranslate"><span class="pre">TopoTune.get_nbhd_cache()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune.interrank_expand"><code class="docutils literal notranslate"><span class="pre">TopoTune.interrank_expand()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune.interrank_gnn_forward"><code class="docutils literal notranslate"><span class="pre">TopoTune.interrank_gnn_forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune.intrarank_expand"><code class="docutils literal notranslate"><span class="pre">TopoTune.intrarank_expand()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune.intrarank_gnn_forward"><code class="docutils literal notranslate"><span class="pre">TopoTune.intrarank_gnn_forward()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune_OneHasse"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune_OneHasse.__init__"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune_OneHasse.aggregate_inter_nbhd"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.aggregate_inter_nbhd()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune_OneHasse.all_nbhds_expand"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.all_nbhds_expand()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune_OneHasse.all_nbhds_gnn_forward"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.all_nbhds_gnn_forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune_OneHasse.forward"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.TopoTune_OneHasse.generate_membership_vectors"><code class="docutils literal notranslate"><span class="pre">TopoTune_OneHasse.generate_membership_vectors()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.customMLP"><code class="docutils literal notranslate"><span class="pre">customMLP</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.customMLP.__init__"><code class="docutils literal notranslate"><span class="pre">customMLP.__init__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.customMLP.flops"><code class="docutils literal notranslate"><span class="pre">customMLP.flops()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.customMLP.forward"><code class="docutils literal notranslate"><span class="pre">customMLP.forward()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#topobench.nn.backbones.customMLP.reset_parameters"><code class="docutils literal notranslate"><span class="pre">customMLP.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#subpackages">Subpackages</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025, Topological-Intelligence Team, Inc..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>